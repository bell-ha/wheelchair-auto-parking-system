import cv2
import numpy as np
import os

# --- [ì„¤ì •] ë§ˆì»¤ ì •ë³´ ë° ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ---
MARKER_SIZE = 25.0  # ì‹¤ì œ ë§ˆì»¤ í¬ê¸° (cm)

# ê´‘ê° ì¹´ë©”ë¼ë¥¼ ìœ„í•œ ì„ì˜ì˜ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê°’
camera_matrix = np.array([[800, 0, 640],
                          [0, 800, 360],
                          [0, 0, 1]], dtype=np.float32)
dist_coeffs = np.zeros((4, 1)) 

def get_aruco_detector():
    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_250)
    parameters = cv2.aruco.DetectorParameters()
    parameters.polygonalApproxAccuracyRate = 0.05
    return cv2.aruco.ArucoDetector(aruco_dict, parameters)

def estimate_pose(frame, corners, ids):
    if ids is not None:
        for i in range(len(ids)):
            # ë§ˆì»¤ì˜ 3D ì¢Œí‘œ ì •ì˜
            obj_points = np.array([[-MARKER_SIZE/2,  MARKER_SIZE/2, 0],
                                   [ MARKER_SIZE/2,  MARKER_SIZE/2, 0],
                                   [ MARKER_SIZE/2, -MARKER_SIZE/2, 0],
                                   [-MARKER_SIZE/2, -MARKER_SIZE/2, 0]], dtype=np.float32)
            
            # PnP ì•Œê³ ë¦¬ì¦˜ ìˆ˜í–‰
            _, rvec, tvec = cv2.solvePnP(obj_points, corners[i], camera_matrix, dist_coeffs)
            
            # --- [ì—ëŸ¬ ìˆ˜ì • í¬ì¸íŠ¸] ê±°ë¦¬ ê³„ì‚° ë°©ì‹ ë³€ê²½ ---
            # np.linalg.normì€ ë²¡í„°ì˜ í¬ê¸°(L2 norm)ë¥¼ ê³„ì‚°í•´ì¤ë‹ˆë‹¤. ì¸ë±ìŠ¤ ì—ëŸ¬ë¡œë¶€í„° ì•ˆì „í•©ë‹ˆë‹¤.
            distance = np.linalg.norm(tvec)
            
            # ê°ë„(Yaw) ê³„ì‚°
            rmat, _ = cv2.Rodrigues(rvec)
            yaw = np.arctan2(rmat[1, 0], rmat[0, 0]) * 180 / np.pi
            
            # í™”ë©´ì— ì •ë³´ í‘œì‹œ
            cv2.aruco.drawDetectedMarkers(frame, [corners[i]], ids[i])
            # ë§ˆì»¤ì˜ ì¢Œì¸¡ ìƒë‹¨ ëª¨ì„œë¦¬ ì¢Œí‘œ ì¶”ì¶œ
            c = corners[i][0][0].astype(int) 
            
            # ê°€ë…ì„±ì„ ìœ„í•´ í…ìŠ¤íŠ¸ ë°°ê²½ ì²˜ë¦¬ ë˜ëŠ” ì„ ëª…í•œ ìƒ‰ìƒ ì‚¬ìš©
            text = f"D: {distance:.1f}cm, Y: {yaw:.1f}deg"
            cv2.putText(frame, text, (c[0], c[1] - 15), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    return frame

def analyze_dual_videos(left_path, rear_path):
    cap_l = cv2.VideoCapture(left_path)
    cap_r = cv2.VideoCapture(rear_path)
    
    if not cap_l.isOpened() or not cap_r.isOpened():
        print("âš ï¸ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/ í´ë”ì— left.mp4ì™€ rear.mp4ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    fps = cap_l.get(cv2.CAP_PROP_FPS)
    w_l, h_l = int(cap_l.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap_l.get(cv2.CAP_PROP_FRAME_HEIGHT))
    w_r, h_r = int(cap_r.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap_r.get(cv2.CAP_PROP_FRAME_HEIGHT))

    h_min = min(h_l, h_r)
    total_w = int(w_l * h_min / h_l) + int(w_r * h_min / h_r)
    
    output_path = "data/detected_pose_combined.mp4"
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (total_w, h_min))

    detector = get_aruco_detector()
    print(f"ğŸ” ê±°ë¦¬/ê°ë„ ë¶„ì„ ì‹œì‘: {output_path} ì €ì¥ ì¤‘...")

    while True:
        ret_l, frame_l = cap_l.read()
        ret_r, frame_r = cap_r.read()

        if not ret_l or not ret_r:
            break

        # í¬ì¦ˆ ì¶”ì • ìˆ˜í–‰
        corners_l, ids_l, _ = detector.detectMarkers(frame_l)
        estimate_pose(frame_l, corners_l, ids_l)

        corners_r, ids_r, _ = detector.detectMarkers(frame_r)
        estimate_pose(frame_r, corners_r, ids_r)

        # í™”ë©´ í•©ì¹˜ê¸°
        f_l_res = cv2.resize(frame_l, (int(w_l * h_min / h_l), h_min))
        f_r_res = cv2.resize(frame_r, (int(w_r * h_min / h_r), h_min))
        combined = cv2.hconcat([f_l_res, f_r_res])

        out.write(combined)
        
        # í™•ì¸ìš© ì¶œë ¥
        display_scale = 1280 / combined.shape[1]
        display_frame = cv2.resize(combined, (0, 0), fx=display_scale, fy=display_scale)
        cv2.imshow("Dual Pose Analysis", display_frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap_l.release()
    cap_r.release()
    out.release()
    cv2.destroyAllWindows()
    print(f"âœ… ë¶„ì„ ì™„ë£Œ: {output_path}")

if __name__ == "__main__":
    analyze_dual_videos("data/left.mp4", "data/rear.mp4")